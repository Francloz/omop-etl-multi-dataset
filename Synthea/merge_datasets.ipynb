{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read diabetes, cvd and not_cvd_diabetes_with_bar \n",
    "patients_diabetes = pd.read_csv('./diabetes/patients.csv')\n",
    "patients_cvd = pd.read_csv('./cvd/patients.csv')\n",
    "patients_not = pd.read_csv('./not_cvd_diabetes_with_var/patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each folder(dataset) has the following csv files: allergies, careplans, \n",
    "# claims_transactions, claims, conditions, devides, encounters, imaging_studies, \n",
    "# immunizations, medications, observations, organizations, Ã tients, payer transitions, \n",
    "# payers, procedures, providers, supplies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new folder for the merged dataset\n",
    "import os\n",
    "if not os.path.exists('trial_data'):\n",
    "    os.makedirs('trial_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allergies\n",
    "allergies_diabetes = pd.read_csv('./diabetes/allergies.csv')\n",
    "allergies_cvd = pd.read_csv('./cvd/allergies.csv')\n",
    "allergies_not = pd.read_csv('./not_cvd_diabetes_with_var/allergies.csv')\n",
    "\n",
    "allergies_diabetes.columns\n",
    "# Merge allergies from the three datasets in one allergies.csv file in trial_data folder\n",
    "allergies = pd.concat([allergies_diabetes, allergies_cvd, allergies_not])\n",
    "allergies.to_csv('./trial_data/allergies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'START', 'STOP', 'PATIENT', 'ENCOUNTER', 'CODE', 'DESCRIPTION',\n",
      "       'REASONCODE', 'REASONDESCRIPTION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Careplans\n",
    "careplans_diabetes = pd.read_csv('./diabetes/careplans.csv')\n",
    "careplans_cvd = pd.read_csv('./cvd/careplans.csv')\n",
    "careplans_not = pd.read_csv('./not_cvd_diabetes_with_var/careplans.csv')\n",
    "\n",
    "print(careplans_diabetes.columns)\n",
    "# Merge careplans from the three datasets in one careplans.csv file in trial_data folder\n",
    "careplans = pd.concat([careplans_diabetes, careplans_cvd, careplans_not])\n",
    "careplans.to_csv('./trial_data/careplans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'CLAIMID', 'CHARGEID', 'PATIENTID', 'TYPE', 'AMOUNT', 'METHOD',\n",
      "       'FROMDATE', 'TODATE', 'PLACEOFSERVICE', 'PROCEDURECODE', 'MODIFIER1',\n",
      "       'MODIFIER2', 'DIAGNOSISREF1', 'DIAGNOSISREF2', 'DIAGNOSISREF3',\n",
      "       'DIAGNOSISREF4', 'UNITS', 'DEPARTMENTID', 'NOTES', 'UNITAMOUNT',\n",
      "       'TRANSFEROUTID', 'TRANSFERTYPE', 'PAYMENTS', 'ADJUSTMENTS', 'TRANSFERS',\n",
      "       'OUTSTANDING', 'APPOINTMENTID', 'LINENOTE', 'PATIENTINSURANCEID',\n",
      "       'FEESCHEDULEID', 'PROVIDERID', 'SUPERVISINGPROVIDERID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Claims_transactions\n",
    "claims_transactions_diabetes = pd.read_csv('./diabetes/claims_transactions.csv')\n",
    "claims_transactions_cvd = pd.read_csv('./cvd/claims_transactions.csv')\n",
    "claims_transactions_not = pd.read_csv('./not_cvd_diabetes_with_var/claims_transactions.csv')\n",
    "\n",
    "print(claims_transactions_diabetes.columns)\n",
    "\n",
    "# Merge claims_transactions from the three datasets in one claims_transactions.csv file in trial_data folder\n",
    "claims_transactions = pd.concat([claims_transactions_diabetes, claims_transactions_cvd, claims_transactions_not])\n",
    "claims_transactions.to_csv('./trial_data/claims_transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'PATIENTID', 'PROVIDERID', 'PRIMARYPATIENTINSURANCEID',\n",
      "       'SECONDARYPATIENTINSURANCEID', 'DEPARTMENTID', 'PATIENTDEPARTMENTID',\n",
      "       'DIAGNOSIS1', 'DIAGNOSIS2', 'DIAGNOSIS3', 'DIAGNOSIS4', 'DIAGNOSIS5',\n",
      "       'DIAGNOSIS6', 'DIAGNOSIS7', 'DIAGNOSIS8', 'REFERRINGPROVIDERID',\n",
      "       'APPOINTMENTID', 'CURRENTILLNESSDATE', 'SERVICEDATE',\n",
      "       'SUPERVISINGPROVIDERID', 'STATUS1', 'STATUS2', 'STATUSP',\n",
      "       'OUTSTANDING1', 'OUTSTANDING2', 'OUTSTANDINGP', 'LASTBILLEDDATE1',\n",
      "       'LASTBILLEDDATE2', 'LASTBILLEDDATEP', 'HEALTHCARECLAIMTYPEID1',\n",
      "       'HEALTHCARECLAIMTYPEID2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Claims\n",
    "claims_diabetes = pd.read_csv('./diabetes/claims.csv')\n",
    "claims_cvd = pd.read_csv('./cvd/claims.csv')\n",
    "claims_not = pd.read_csv('./not_cvd_diabetes_with_var/claims.csv')\n",
    "\n",
    "print(claims_diabetes.columns)\n",
    "\n",
    "# Merge claims from the three datasets in one claims.csv file in trial_data folder\n",
    "claims = pd.concat([claims_diabetes, claims_cvd, claims_not])\n",
    "claims.to_csv('./trial_data/claims.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['START', 'STOP', 'PATIENT', 'ENCOUNTER', 'SYSTEM', 'CODE',\n",
      "       'DESCRIPTION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Conditions\n",
    "conditions_diabetes = pd.read_csv('./diabetes/conditions.csv')\n",
    "conditions_cvd = pd.read_csv('./cvd/conditions.csv')\n",
    "conditions_not = pd.read_csv('./not_cvd_diabetes_with_var/conditions.csv')\n",
    "\n",
    "print(conditions_diabetes.columns)\n",
    "\n",
    "# Merge conditions from the three datasets in one conditions.csv file in trial_data folder\n",
    "conditions = pd.concat([conditions_diabetes, conditions_cvd, conditions_not])\n",
    "conditions.to_csv('./trial_data/conditions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['START', 'STOP', 'PATIENT', 'ENCOUNTER', 'CODE', 'DESCRIPTION', 'UDI'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Devices\n",
    "devices_diabetes = pd.read_csv('./diabetes/devices.csv')\n",
    "devices_cvd = pd.read_csv('./cvd/devices.csv')\n",
    "devices_not = pd.read_csv('./not_cvd_diabetes_with_var/devices.csv')\n",
    "\n",
    "print(devices_diabetes.columns)\n",
    "\n",
    "# Merge devices from the three datasets in one devices.csv file in trial_data folder\n",
    "devices = pd.concat([devices_diabetes, devices_cvd, devices_not])\n",
    "devices.to_csv('./trial_data/devices.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'START', 'STOP', 'PATIENT', 'ORGANIZATION', 'PROVIDER', 'PAYER',\n",
      "       'ENCOUNTERCLASS', 'CODE', 'DESCRIPTION', 'BASE_ENCOUNTER_COST',\n",
      "       'TOTAL_CLAIM_COST', 'PAYER_COVERAGE', 'REASONCODE',\n",
      "       'REASONDESCRIPTION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Encounters\n",
    "encounters_diabetes = pd.read_csv('./diabetes/encounters.csv')\n",
    "encounters_cvd = pd.read_csv('./cvd/encounters.csv')\n",
    "encounters_not = pd.read_csv('./not_cvd_diabetes_with_var/encounters.csv')\n",
    "\n",
    "print(encounters_diabetes.columns)\n",
    "\n",
    "# Merge encounters from the three datasets in one encounters.csv file in trial_data folder\n",
    "encounters = pd.concat([encounters_diabetes, encounters_cvd, encounters_not])\n",
    "encounters.to_csv('./trial_data/encounters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'DATE', 'PATIENT', 'ENCOUNTER', 'SERIES_UID', 'BODYSITE_CODE',\n",
      "       'BODYSITE_DESCRIPTION', 'MODALITY_CODE', 'MODALITY_DESCRIPTION',\n",
      "       'INSTANCE_UID', 'SOP_CODE', 'SOP_DESCRIPTION', 'PROCEDURE_CODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Imaging_studies\n",
    "imaging_studies_diabetes = pd.read_csv('./diabetes/imaging_studies.csv')\n",
    "imaging_studies_cvd = pd.read_csv('./cvd/imaging_studies.csv')\n",
    "imaging_studies_not = pd.read_csv('./not_cvd_diabetes_with_var/imaging_studies.csv')\n",
    "\n",
    "print(imaging_studies_diabetes.columns)\n",
    "\n",
    "# Merge imaging_studies from the three datasets in one imaging_studies.csv file in trial_data folder\n",
    "imaging_studies = pd.concat([imaging_studies_diabetes, imaging_studies_cvd, imaging_studies_not])\n",
    "imaging_studies.to_csv('./trial_data/imaging_studies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', 'PATIENT', 'ENCOUNTER', 'CODE', 'DESCRIPTION', 'BASE_COST'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Immunizations\n",
    "immunizations_diabetes = pd.read_csv('./diabetes/immunizations.csv')\n",
    "immunizations_cvd = pd.read_csv('./cvd/immunizations.csv')\n",
    "immunizations_not = pd.read_csv('./not_cvd_diabetes_with_var/immunizations.csv')\n",
    "\n",
    "print(immunizations_diabetes.columns)\n",
    "\n",
    "# Merge immunizations from the three datasets in one immunizations.csv file in trial_data folder\n",
    "immunizations = pd.concat([immunizations_diabetes, immunizations_cvd, immunizations_not])\n",
    "immunizations.to_csv('./trial_data/immunizations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['START', 'STOP', 'PATIENT', 'PAYER', 'ENCOUNTER', 'CODE', 'DESCRIPTION',\n",
      "       'BASE_COST', 'PAYER_COVERAGE', 'DISPENSES', 'TOTALCOST', 'REASONCODE',\n",
      "       'REASONDESCRIPTION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Medications\n",
    "medications_diabetes = pd.read_csv('./diabetes/medications.csv')\n",
    "medications_cvd = pd.read_csv('./cvd/medications.csv')\n",
    "medications_not = pd.read_csv('./not_cvd_diabetes_with_var/medications.csv')\n",
    "\n",
    "print(medications_diabetes.columns)\n",
    "\n",
    "# Merge medications from the three datasets in one medications.csv file in trial_data folder\n",
    "medications = pd.concat([medications_diabetes, medications_cvd, medications_not])\n",
    "medications.to_csv('./trial_data/medications.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', 'PATIENT', 'ENCOUNTER', 'CATEGORY', 'CODE', 'DESCRIPTION',\n",
      "       'VALUE', 'UNITS', 'TYPE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Observations\n",
    "observations_diabetes = pd.read_csv('./diabetes/observations.csv')\n",
    "observations_cvd = pd.read_csv('./cvd/observations.csv')\n",
    "observations_not = pd.read_csv('./not_cvd_diabetes_with_var/observations.csv')\n",
    "\n",
    "print(observations_diabetes.columns)\n",
    "\n",
    "# Merge observations from the three datasets in one observations.csv file in trial_data folder\n",
    "observations = pd.concat([observations_diabetes, observations_cvd, observations_not])\n",
    "observations.to_csv('./trial_data/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'NAME', 'ADDRESS', 'CITY', 'STATE', 'ZIP', 'LAT', 'LON', 'PHONE',\n",
      "       'REVENUE', 'UTILIZATION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Organizations\n",
    "organizations_diabetes = pd.read_csv('./diabetes/organizations.csv')\n",
    "organizations_cvd = pd.read_csv('./cvd/organizations.csv')\n",
    "observations_not = pd.read_csv('./not_cvd_diabetes_with_var/organizations.csv')\n",
    "\n",
    "print(organizations_diabetes.columns)\n",
    "\n",
    "# Merge organizations from the three datasets in one organizations.csv file in trial_data folder\n",
    "organizations = pd.concat([organizations_diabetes, organizations_cvd, observations_not])\n",
    "organizations.to_csv('./trial_data/organizations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'BIRTHDATE', 'DEATHDATE', 'SSN', 'DRIVERS', 'PASSPORT', 'PREFIX',\n",
      "       'FIRST', 'MIDDLE', 'LAST', 'SUFFIX', 'MAIDEN', 'MARITAL', 'RACE',\n",
      "       'ETHNICITY', 'GENDER', 'BIRTHPLACE', 'ADDRESS', 'CITY', 'STATE',\n",
      "       'COUNTY', 'FIPS', 'ZIP', 'LAT', 'LON', 'HEALTHCARE_EXPENSES',\n",
      "       'HEALTHCARE_COVERAGE', 'INCOME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Patients\n",
    "patients_diabetes = pd.read_csv('./diabetes/patients.csv')\n",
    "patients_cvd = pd.read_csv('./cvd/patients.csv')\n",
    "patients_not = pd.read_csv('./not_cvd_diabetes_with_var/patients.csv')\n",
    "\n",
    "print(patients_diabetes.columns)\n",
    "\n",
    "# Merge patients from the three datasets in one patients.csv file in trial_data folder\n",
    "patients = pd.concat([patients_diabetes, patients_cvd, patients_not])\n",
    "patients.to_csv('./trial_data/patients.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT', 'MEMBERID', 'START_DATE', 'END_DATE', 'PAYER',\n",
      "       'SECONDARY_PAYER', 'PLAN_OWNERSHIP', 'OWNER_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Payer_transitions\n",
    "payer_transitions_diabetes = pd.read_csv('./diabetes/payer_transitions.csv')\n",
    "payer_transitions_cvd = pd.read_csv('./cvd/payer_transitions.csv')\n",
    "payer_transitions_not = pd.read_csv('./not_cvd_diabetes_with_var/payer_transitions.csv')\n",
    "\n",
    "print(payer_transitions_diabetes.columns)\n",
    "\n",
    "# Merge payer_transitions from the three datasets in one payer_transitions.csv file in trial_data folder\n",
    "payer_transitions = pd.concat([payer_transitions_diabetes, payer_transitions_cvd, payer_transitions_not])\n",
    "payer_transitions.to_csv('./trial_data/payer_transitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'NAME', 'OWNERSHIP', 'ADDRESS', 'CITY', 'STATE_HEADQUARTERED',\n",
      "       'ZIP', 'PHONE', 'AMOUNT_COVERED', 'AMOUNT_UNCOVERED', 'REVENUE',\n",
      "       'COVERED_ENCOUNTERS', 'UNCOVERED_ENCOUNTERS', 'COVERED_MEDICATIONS',\n",
      "       'UNCOVERED_MEDICATIONS', 'COVERED_PROCEDURES', 'UNCOVERED_PROCEDURES',\n",
      "       'COVERED_IMMUNIZATIONS', 'UNCOVERED_IMMUNIZATIONS', 'UNIQUE_CUSTOMERS',\n",
      "       'QOLS_AVG', 'MEMBER_MONTHS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Payers\n",
    "payers_diabetes = pd.read_csv('./diabetes/payers.csv')\n",
    "payers_cvd = pd.read_csv('./cvd/payers.csv')\n",
    "payers_not = pd.read_csv('./not_cvd_diabetes_with_var/payers.csv')\n",
    "\n",
    "print(payers_diabetes.columns)\n",
    "\n",
    "# Merge payers from the three datasets in one payers.csv file in trial_data folder\n",
    "payers = pd.concat([payers_diabetes, payers_cvd, payers_not])\n",
    "payers.to_csv('./trial_data/payers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['START', 'STOP', 'PATIENT', 'ENCOUNTER', 'SYSTEM', 'CODE',\n",
      "       'DESCRIPTION', 'BASE_COST', 'REASONCODE', 'REASONDESCRIPTION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Procedures\n",
    "procedures_diabetes = pd.read_csv('./diabetes/procedures.csv')\n",
    "procedures_cvd = pd.read_csv('./cvd/procedures.csv')\n",
    "procedures_not = pd.read_csv('./not_cvd_diabetes_with_var/procedures.csv')\n",
    "\n",
    "print(procedures_diabetes.columns)\n",
    "\n",
    "# Merge procedures from the three datasets in one procedures.csv file in trial_data folder\n",
    "procedures = pd.concat([procedures_diabetes, procedures_cvd, procedures_not])\n",
    "procedures.to_csv('./trial_data/procedures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ORGANIZATION', 'NAME', 'GENDER', 'SPECIALITY', 'ADDRESS', 'CITY',\n",
      "       'STATE', 'ZIP', 'LAT', 'LON', 'ENCOUNTERS', 'PROCEDURES'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Providers\n",
    "providers_diabetes = pd.read_csv('./diabetes/providers.csv')\n",
    "providers_cvd = pd.read_csv('./cvd/providers.csv')\n",
    "providers_not = pd.read_csv('./not_cvd_diabetes_with_var/providers.csv')\n",
    "\n",
    "print(providers_diabetes.columns)\n",
    "\n",
    "# Merge providers from the three datasets in one providers.csv file in trial_data folder\n",
    "providers = pd.concat([providers_diabetes, providers_cvd, providers_not])\n",
    "providers.to_csv('./trial_data/providers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', 'PATIENT', 'ENCOUNTER', 'CODE', 'DESCRIPTION', 'QUANTITY'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Supplies\n",
    "supplies_diabetes = pd.read_csv('./diabetes/supplies.csv')\n",
    "supplies_cvd = pd.read_csv('./cvd/supplies.csv')\n",
    "supplies_not = pd.read_csv('./not_cvd_diabetes_with_var/supplies.csv')\n",
    "\n",
    "print(supplies_diabetes.columns)\n",
    "\n",
    "# Merge supplies from the three datasets in one supplies.csv file in trial_data folder\n",
    "supplies = pd.concat([supplies_diabetes, supplies_cvd, supplies_not])\n",
    "supplies.to_csv('./trial_data/supplies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len diabetes: 362\n",
      "len cvd: 249\n",
      "len not_cvd: 381\n",
      "len trial_data: 992\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Print len diabetes and len trial_data\n",
    "print('len diabetes:', len(patients_diabetes))\n",
    "print('len cvd:', len(patients_cvd))\n",
    "print('len not_cvd:', len(patients_not))\n",
    "print('len trial_data:', len(patients))\n",
    "\n",
    "# Print true if the sum of the three datasets observations is equal to the merged dataset\n",
    "print(len(observations_diabetes) + len(observations_cvd) + len(observations_not) == len(observations))\n",
    "\n",
    "# Print true if the sum of the three datasets medications is equal to the merged dataset\n",
    "print(len(medications_diabetes) + len(medications_cvd) + len(medications_not) == len(medications))\n",
    "\n",
    "# Print true if the sum of the three datasets conditions is equal to the merged dataset\n",
    "print(len(conditions_diabetes) + len(conditions_cvd) + len(conditions_not) == len(conditions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT</th>\n",
       "      <th>MEMBERID</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>PAYER</th>\n",
       "      <th>SECONDARY_PAYER</th>\n",
       "      <th>PLAN_OWNERSHIP</th>\n",
       "      <th>OWNER_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aea23030-9b47-caa0-d0d7-22fe7363af4f</td>\n",
       "      <td>a821883e-ba5e-9bb5-971b-5d3275b5dc18</td>\n",
       "      <td>2014-03-12T02:59:21Z</td>\n",
       "      <td>2015-03-11T02:59:21Z</td>\n",
       "      <td>26aab0cd-6aba-3e1b-ac5b-05c8867e762c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self</td>\n",
       "      <td>Cory323 Bauch723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aea23030-9b47-caa0-d0d7-22fe7363af4f</td>\n",
       "      <td>201c711e-e556-ea96-b7cb-8e6f587bce6f</td>\n",
       "      <td>2015-03-11T02:59:21Z</td>\n",
       "      <td>2016-03-09T02:59:21Z</td>\n",
       "      <td>26aab0cd-6aba-3e1b-ac5b-05c8867e762c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self</td>\n",
       "      <td>Cory323 Bauch723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aea23030-9b47-caa0-d0d7-22fe7363af4f</td>\n",
       "      <td>a834688b-6478-eafd-a9ad-d39c065fe50d</td>\n",
       "      <td>2016-03-09T02:59:21Z</td>\n",
       "      <td>2017-03-08T02:59:21Z</td>\n",
       "      <td>26aab0cd-6aba-3e1b-ac5b-05c8867e762c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self</td>\n",
       "      <td>Cory323 Bauch723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aea23030-9b47-caa0-d0d7-22fe7363af4f</td>\n",
       "      <td>d836348b-1503-3a87-2390-c404a35d9651</td>\n",
       "      <td>2017-03-08T02:59:21Z</td>\n",
       "      <td>2018-03-07T02:59:21Z</td>\n",
       "      <td>26aab0cd-6aba-3e1b-ac5b-05c8867e762c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self</td>\n",
       "      <td>Cory323 Bauch723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aea23030-9b47-caa0-d0d7-22fe7363af4f</td>\n",
       "      <td>e1172f69-d073-f5a1-c603-9da8148df144</td>\n",
       "      <td>2018-03-07T02:59:21Z</td>\n",
       "      <td>2019-03-13T02:59:21Z</td>\n",
       "      <td>26aab0cd-6aba-3e1b-ac5b-05c8867e762c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self</td>\n",
       "      <td>Cory323 Bauch723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                PATIENT                              MEMBERID  \\\n",
       "0  aea23030-9b47-caa0-d0d7-22fe7363af4f  a821883e-ba5e-9bb5-971b-5d3275b5dc18   \n",
       "1  aea23030-9b47-caa0-d0d7-22fe7363af4f  201c711e-e556-ea96-b7cb-8e6f587bce6f   \n",
       "2  aea23030-9b47-caa0-d0d7-22fe7363af4f  a834688b-6478-eafd-a9ad-d39c065fe50d   \n",
       "3  aea23030-9b47-caa0-d0d7-22fe7363af4f  d836348b-1503-3a87-2390-c404a35d9651   \n",
       "4  aea23030-9b47-caa0-d0d7-22fe7363af4f  e1172f69-d073-f5a1-c603-9da8148df144   \n",
       "\n",
       "             START_DATE              END_DATE  \\\n",
       "0  2014-03-12T02:59:21Z  2015-03-11T02:59:21Z   \n",
       "1  2015-03-11T02:59:21Z  2016-03-09T02:59:21Z   \n",
       "2  2016-03-09T02:59:21Z  2017-03-08T02:59:21Z   \n",
       "3  2017-03-08T02:59:21Z  2018-03-07T02:59:21Z   \n",
       "4  2018-03-07T02:59:21Z  2019-03-13T02:59:21Z   \n",
       "\n",
       "                                  PAYER SECONDARY_PAYER PLAN_OWNERSHIP  \\\n",
       "0  26aab0cd-6aba-3e1b-ac5b-05c8867e762c             NaN           Self   \n",
       "1  26aab0cd-6aba-3e1b-ac5b-05c8867e762c             NaN           Self   \n",
       "2  26aab0cd-6aba-3e1b-ac5b-05c8867e762c             NaN           Self   \n",
       "3  26aab0cd-6aba-3e1b-ac5b-05c8867e762c             NaN           Self   \n",
       "4  26aab0cd-6aba-3e1b-ac5b-05c8867e762c             NaN           Self   \n",
       "\n",
       "         OWNER_NAME  \n",
       "0  Cory323 Bauch723  \n",
       "1  Cory323 Bauch723  \n",
       "2  Cory323 Bauch723  \n",
       "3  Cory323 Bauch723  \n",
       "4  Cory323 Bauch723  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "payer_transitions = pd.read_csv('./trial_data/payer_transitions.csv')\n",
    "payer_transitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/pm7rdrpx1tx44znvg04hlryc0000gn/T/ipykernel_9319/1765661832.py:2: DtypeWarning: Columns (5,6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  concept = pd.read_csv('/Users/juliasanchez/Desktop/TFM/CDM5VOCAB/CONCEPT.csv', delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "# read concept and concept_ancerstor\n",
    "concept = pd.read_csv('/Users/juliasanchez/Desktop/TFM/CDM5VOCAB/CONCEPT.csv', delimiter='\\t')\n",
    "concept_ancestor = pd.read_csv('/Users/juliasanchez/Desktop/TFM/CDM5VOCAB/CONCEPT_ANCESTOR.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept_name</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>vocabulary_id</th>\n",
       "      <th>concept_class_id</th>\n",
       "      <th>standard_concept</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>valid_end_date</th>\n",
       "      <th>invalid_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>847020</th>\n",
       "      <td>21495357</td>\n",
       "      <td>Escherichia sp</td>\n",
       "      <td>Measurement</td>\n",
       "      <td>LOINC</td>\n",
       "      <td>LOINC Hierarchy</td>\n",
       "      <td>C</td>\n",
       "      <td>LP30565-3</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        concept_id    concept_name    domain_id vocabulary_id  \\\n",
       "847020    21495357  Escherichia sp  Measurement         LOINC   \n",
       "\n",
       "       concept_class_id standard_concept concept_code  valid_start_date  \\\n",
       "847020  LOINC Hierarchy                C    LP30565-3          19700101   \n",
       "\n",
       "        valid_end_date invalid_reason  \n",
       "847020        20991231            NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 21495357\n",
    "# Check if id in CONCEPT_ID\n",
    "concept[concept['concept_id'] == id]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
